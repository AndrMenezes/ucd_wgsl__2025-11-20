---
title: "Bayesian nonparametric models for sparse count-compositional data using ensembles of regression trees"
author:
  - "<strong>Andr√© F. B. Menezes<strong> -- MU"
  - Prof. Andrew Parnell -- UCD
  - Dr. Keefe Murphy -- MU
date: "Working Group on Statistical Learning, UCD, November 20, 2025"
output:
  xaringan::moon_reader:
    css: ["default", "./config/sydney.css", "./config/sydney-fonts.css"]
    self_contained: FALSE
    mathjax: default
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: TRUE
      countIncrementalSlides: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center",
                      dev = "svg", fig.width = 10, fig.height = 6)
library(RefManageR)
library(ggplot2)
library(cowplot)
library(xtable)
library(dplyr)
theme_set(
  theme_cowplot(font_size = 16, font_family = "Palatino") +
    background_grid() +
    theme(legend.position = "top")
)
options(digits = 4L)

BibOptions(check.entries = FALSE, bib.style = "authoryear", style = "markdown",
           hyperlink = TRUE, dashed = TRUE, max.names = 1, longnamesfirst = FALSE)
bib <- ReadBib("./references.bib", check = FALSE)
data_pollen <- read.csv(file = file.path("./data", "rs11_pollen.csv"))
data_pollen <- dplyr::as_tibble(data_pollen)
sp <- c("Pinus.D", "Betula", "Gramineae", "Picea", "Quercus.D", "Alnus", "Cyperaceae",
        "Chenopodiaceae", "Artemisia", "Quercus.E", "Salix", "Juniperus", "Ericales",
        "Fagus", "Abies", "Olea", "Ulmus", "Corylus", "Ostrya", "Pinus.H", "Cedrus",
        "Carpinus", "Pistacia", "Castanea", "Larix", "Tilia", "Ephedra", "Phillyrea")
data_pollen$specie <- forcats::fct_relevel(data_pollen$specie, sp)
data_pollen

data_pollen_wide <- data_pollen |>
  dplyr::select(-c(category, prop)) |>
  dplyr::mutate(total = as.integer(total)) |>
  tidyr::pivot_wider(names_from = specie, values_from = total) |>
  dplyr::select(gdd5, mtco, aet.pet, dplyr::all_of(sp))

tab_emp <- cbind(
  avg = colMeans(data_pollen_wide[, -(1:3)]),
  di = apply(data_pollen_wide[, -(1:3)], 2, var)/colMeans(data_pollen_wide[, -(1:3)]))
range(tab_emp[, 2])
```

# Outline

- Introduction

- Zero-inflation in count-compositional data
<!-- Zero-and-$N$-inflated count-compositional distributions -->

- Bayesian nonparametric models for sparse count-compositional data
  - The BART prior
  - The novel Bayesian nonparametric models
  - Inference
  - Simulated example

- Modern pollen-climate application

- Conclusions

---
# What is count-compositional data?

> Multivariate counts constrained by a random or fixed total.

- The data are usually collected in a matrix $\mathbf{Y} \in \mathbb{N}^{n\times d}_0$,
with $n$ samples and $d$ categories.

- Each row is a random vector $\mathbf{Y}_i = (Y_{i1}, \ldots, Y_{id})$
with non-negative integer values defined in the discrete simplex space:
$$\mathbb{S}_N^d = \left\{\mathbf{Y}_i \in \left(0, 1, \ldots, N_i\right)^d; \sum_{j=1}^d Y_{ij}=N_i\right\}.$$


- Examples include:
  - pollen counts observed in sediments dating from several species.
  - genomic sequencing data (microbiome, single-cell RNA).
  - total votes of each candidate for the Irish presidential election.



---
## Motivating example

- Modern pollen-climate data: $n=7832$ samples, $d=28$ pollen species, $p=3$ climate covariates, total counts $N_i \in \lbrack74, 1003\rbrack$ `r Citep(bib, c("Haslett2006", "SalterTownshend2012", "Parnell2015"))`.

```{r glimpse}
data_pollen |>
  # dplyr::filter(id < 4) |>
  dplyr::select(-c(category, prop)) |>
  dplyr::mutate(total = as.integer(total)) |>
  tidyr::pivot_wider(names_from = specie, values_from = total) |>
  dplyr::select(gdd5, mtco, aet.pet, dplyr::all_of(sp))
#    |>
#   dplyr::glimpse()
```

---
## Motivating example

```{r map-location, out.width="100%", fig.align="center"}
knitr::include_graphics("./figures/mapping_location_total_zero.png")
```

---
## Motivating example

```{r plot-pollen, echo = FALSE, out.width="90%"}
data_pollen |>
  dplyr::filter(specie %in% sp[1:9]) |>
  ggplot(aes(x = mtco, y = prop)) +
  facet_wrap(~specie) +
  geom_point(alpha = 0.3, size = 0.8) +
  geom_rug(data = dplyr::filter(data_pollen, specie %in% sp[1:9], total == 0),
           aes(y = NA_real_), col = "red", alpha = 0.5) +
  labs(y = "Pollen composition", x = "Mean temperature of coldest month (MTCO)")
```

---
## Key features of pollen-climate count-compositional data

<!-- - High-dimension: $d = 28$ pollen species. -->

- Sparse: $63.21\%$ of counts are zero.
  - $N$-inflated observations:
```{r n-inflated}
dplyr::select(dplyr::filter(data_pollen, prop == 1), id, specie, total, prop, 
              gdd5, mtco, aet.pet, longitude, latitude, altitude)
```

- Heterogeneity: $\operatorname{DI}(Y_j)=\operatorname{Var}(Y_j)/\mathbb{E}(Y_j)$ ranging from $41.15$ (_Ostrya_) and $470.18$ (_Cedrus_),
indicating overdispersion.

- Unknown relationship between the climate variables and the pollen composition.
  - Gaussian markov random field (GMRF) have been used as a smooth prior function in one, two and three-dimensional climate space `r Citep(bib, c("Haslett2006", "SalterTownshend2012", "Sweeney2012", "Tipton2019"))`.

<!-- , and the taxa-specific excess of zeros. -->


---
## Related work

> - **Paleoclimate studies**: break the multinomial into independent univariate 
components using expert-informed hierarchical category (pollen species) structures.
`r Citep(bib, c("SalterTownshend2012", "Sweeney2012"))`.
> - **Microbiome studies**: explicitly account for zero-inflation in count-composition data,
but rely simple linear regression structure:
`r Citep(bib, c("Tang2018", "Zeng2023", "Koslovsky2023"))`.

--

.font120[Current work]

> 1. A unified framework for zero-inflation in count-compositional data `r Citep(bib, "Menezes2025")`.
> 2. Bayesian nonparametric models that jointly address zero-inflation, overdispersion, unobserved latent effects, and complex covariate relationships.

---
count: false
class: middle, inverse
# Zero-inflation in count-compositional data

---
# Zero-inflation in count-compositional data

- Zeros may have different meanings `r Citep(bib, "BlascoMoreno2019")`:
  - Sampling zeros: due to sampling variability.
  - Structural zeros: related to constraints on experimental conditions (data collection). 

- The common probability distributions (multinomial and Dirichlet-multinomial)
for count-compositional can not handle excess of zeros.

--

- Excess zeros can occur in a single category or across multiple categories.
  
  - $d = 5$ and $N = 12$: $\mathbf{Y}_i = (2, 3, 0, 4, 3)$, $\mathbf{Y}_i = (9, 3, 0, 0, 0)$ or
$\mathbf{Y}_i = (12, 0, 0, 0, 0)$.

  - There are $2^d - 1$ different settings where zeros can occur in the random vector $\mathbf{Y}_i \in \mathbb{S}^d_{N_i}$.

  - In extreme cases where zeros co-occur in all but one category, the count for the
remaining category will coincide with the number of trials, $N_i$.

---
# The zero-and-N-inflated multinomial distribution

- $\mathbf{Y}_i \sim \operatorname{Multinomial}\left\lbrack N_i, \boldsymbol{\theta}\right\rbrack$,
where 
$\boldsymbol{\theta} = (\theta_1, \ldots, \theta_d)$ are the *population-level* count
probabilities defined on the continuous simplex
$\{\pmb{\theta}\in\mathbb{R}^d; \theta_j > 0, \sum_{j=1}^d \theta_j=1\}$.

--
- Reparameterise $\theta_j=\lambda_j/\sum_{k=1}^d \lambda_k$ and introduce the latent 
variable $(\phi_i \mid \boldsymbol{\lambda}, \mathbf{y}_i) \sim \operatorname{Gamma}\lbrack N_i, \sum_{j=1}^d\lambda_j\rbrack$,
such that the joint density of $\mathbf{Y}_i$ and $\phi_i$ is `r Citep(bib, "Baker1994")`:
$$p(\mathbf{y}_i,\phi_i;\boldsymbol{\lambda})=\dfrac{N_i!\phi_i^{N_i-1}}{\Gamma(N_i)}\prod_{j=1}^d\left\lbrack\dfrac{\lambda_j^{y_{ij}}e^{-\lambda_j\phi_i}}{y_{ij}!}\right\rbrack.$$

--
- We extend this to a zero-inflated Poisson form with a vector
$\boldsymbol{\zeta} = (\zeta_1, \ldots, \zeta_d)$ of 
*population-level* structural zero probabilities
for each category, such that $\zeta_j \in \lbrack 0, 1 \rbrack$, i.e.
$$p(\mathbf{y}_i,\phi; \boldsymbol{\lambda}, \boldsymbol{\zeta}) =
\dfrac{N_i!\,\phi^{N_i - 1}}{\Gamma(N_i)}\,\prod_{j=1}^d \left\lbrack
\zeta_j\,I_0(y_{ij}) + (1 - \zeta_j)\,\dfrac{\lambda_j^{y_{ij}}\,e^{-\lambda_j\,\phi_i}}{y_{ij}!}
\right\rbrack$$
and then integrate out $\phi_i$ to obtain the zero-and-_N_-inflated multinomial (ZANIM) distribution.

---
# ZANIM finite mixture representation

$$\begin{align}\Pr\lbrack
\mathbf{Y}_i = \mathbf{y}_i; \pmb{\theta}, \pmb{\zeta}\rbrack &= \eta_d\,\binom{N}{y_{i1} \dots y_{id}}\,
\prod_{j=1}^d
\theta_j^{y_{ij}} \leftarrow \fbox{Multinomial component}\\
\fbox{All-inflation component}\rightarrow  &\phantom{=}~+\eta_0\,\prod_{j=1}^{d}\,I_0(y_{ij})\\
\fbox{N-inflation components}\rightarrow &\phantom{=}~+
\sum_{j=1}^{d}\,
\eta_{N}^{(j)}
\left\lbrack 
I_0\left(\sum_{k\colon k \neq j} y_{ik} \right)\,
\right\rbrack \\
\fbox{Reduced multinomials components}\rightarrow 
&\phantom{=}~+
\sum_{\mathcal{K} \in \mathfrak{K}} 
\eta_{\mathcal{K}}
\left\lbrack
I_0\left(\sum_{k \in \mathcal{K}} y_{ik}\right) 
\binom{N}{\{y_{ij}\}_{j \notin \mathcal{K}}} 
\prod_{j \notin \mathcal{K}} \left( \theta_j^{\mathcal{K}} \right)^{y_{ij}}
\right\rbrack  
\end{align}$$
for $\mathbf{y}_i \in \mathbb{S}^d_{N_i} \cup \mathbf{0}_d$,
where
$\theta_j^{\mathcal{K}} = \dfrac{\theta_j}{1 - \sum_{\ell \in \mathcal{K}}\,\theta_{\ell}}$,
and 
$\mathfrak{K} = \{\mathcal{K} \subseteq \{1,\ldots,d\}; 1 \leq \lvert\mathcal{K}\rvert \leq d-2\}$.

--
> We do not need to evaluate ALL $2^d$ mixture components and there are only 
$2d$ parameters, as the mixture weights $\boldsymbol{\eta}$ are simple functions of
the $\boldsymbol{\zeta}$ parameters.

---
## Stochastic representation

If $\mathbf{Y}_i \sim \operatorname{ZANIM}_d\lbrack N_i, \boldsymbol{\theta}, \boldsymbol{\zeta} \rbrack$,
then $\mathbf{Y}$ has the stochastic representation:
$$\begin{align*}
(z_{ij} \mid \zeta_{j}) & \overset{\operatorname{ind.}}{\sim} \operatorname{Bernoulli}\lbrack 1 - \zeta_j \rbrack, \quad j=1,\ldots, d\\
(\mathbf{Y}_i \mid N_i, \boldsymbol{\theta}, \boldsymbol{z}_i) &\sim
\begin{cases} \delta_{\mathbf{0}_d}(\cdot) & \textrm{if} \: z_{ij} = 0 \: \forall j\\
\operatorname{Multinomial}_d\left\lbrack N, \dfrac{z_{i1}\theta_1}{\sum_{k=1}^dz_{ik}\theta_k}, \ldots, \dfrac{z_{id}\theta_d}{\sum_{k=1}^dz_{ik}\theta_k}\right\rbrack
& \textrm{otherwise}.
\end{cases}
\end{align*}$$

> We refer to $$\vartheta_{ij} = \frac{z_{ij}\theta_j}{\sum_{k=1}^d z_{ik}\theta_k}$$
as the *individual-level* count probabilities, for $i\in\{1,\ldots,n\}$ and $j\in\{1,\ldots,d\}$.

---
### Marginal PMF $\pmb{\theta} = (0.05, 0.70, 0.25)$, $\pmb{\zeta} = (0.05, 0.15, 0.10)$, and $N=30$

```{r marginal-pmf, fig.width = 12, fig.height = 4}
d <- 3L
m <- 30L
theta <- c(0.05, 0.70, 0.25)
zeta <- c(0.10, 0.15, 0.05)

xx <- seq.int(0, m)
pmf_zanim <- matrix(data = 0L, nrow = length(xx), ncol = d)
pmf_mult <- matrix(data = 0L, nrow = length(xx), ncol = d)

for (i in seq_along(xx)) {
  pmf_zanim[i, 1L] <- zanim::dzanim_marginal(x = xx[i], size = m, prob = theta,
                                      zeta = zeta, j = 1L)
  pmf_zanim[i, 2L] <- zanim::dzanim_marginal(x = xx[i], size = m, prob = theta,
                                      zeta = zeta, j = 2L)
  pmf_zanim[i, 3L] <- zanim::dzanim_marginal(x = xx[i], size = m, prob = theta,
                                      zeta = zeta, j = 3L)
}
pmf_mult[, 1L] <- dbinom(x = xx, size = m, prob = theta[1L])
pmf_mult[, 2L] <- dbinom(x = xx, size = m, prob = theta[2L])
pmf_mult[, 3L] <- dbinom(x = xx, size = m, prob = theta[3L])


data_pmf_zanim <- dplyr::tibble(dist = "ZANIM",
                                x = rep(xx, d),
                                pmf = c(pmf_zanim),
                                cat = rep(paste0("j == ", 1:d),
                                          each = length(xx)))
data_pmf_mult <- dplyr::tibble(dist = "Multinomial",
                               x = rep(xx, d),
                               pmf = c(pmf_mult),
                               cat = rep(paste0("j == ", 1:d),
                                         each = length(xx)))
data_pmf <- rbind(data_pmf_mult, data_pmf_zanim)
ggplot(data = dplyr::filter(data_pmf),
            aes(x = x, y = pmf, col = dist)) +
  facet_wrap(~cat, nrow = 1L, scales = "free", labeller = label_parsed) +
  geom_pointrange(mapping = aes(ymin = 0, ymax = pmf),
                  size = 0.12, fill = 0.2) +
  scale_x_continuous(breaks = scales::pretty_breaks(8)) +
  labs(x = "k", y = latex2exp::TeX(r'($\Pr\lbrack Y_j = k \rbrack$)'),
       col = "") +
  colorspace::scale_color_discrete_qualitative()
```

--
> We also show that the zero-and-_N_-inflated Dirichlet-multinomial (ZANIDM) distribution
intoduced by `r Citet(bib, "Koslovsky2023")`
admits a finite mixture representation and we derive moments, marginals, and fully conjugate Bayesian inference schemes for both distributions.

---
# [Menezes, Parnell, and Murphy (2025)]()

```{r paper-jmva, out.width="50%"}
knitr::include_graphics("./figures/paper_jmva.png")
```

> Menezes, A.F., Parnell, A.C., Murphy, K., 2025.
Finite mixture representations of zero-and-_N_-inflated distributions for count-compositional data. Journal of Multivariate Analysis 210, 105492. doi:10.1016/j.jmva.6342025.105492.

---
count: false
class: middle, inverse
# The novel Bayesian nonparametric models

---
# The Bayesian additive regression trees (BART) prior

.font75[

- BART is Bayesian nonparametric prior that represents 
an unknown function $f(\mathbf{x}_i)$ of interest as a sum of decision trees `r Citep(bib, "Chipman2010")`:
$$f(\mathbf{x}_i) = \sum_{h=1}^{m}g(\mathbf{x}_i, \mathcal{T}_h, \mathcal{M}_h),$$
where $g(\mathbf{x}_i, \mathcal{T}_h, \mathcal{M}_h)$ denotes a binary decision
tree parametrised by:
  - Binary tree topology $\mathcal{T}_h$ with leaf and branch nodes
  $\mathcal{L}_h$ and $\mathcal{B}_h$, respectively.
  - In each branch node $b\in \mathcal{B}_h$ there is a spitting rule of the form
$\lbrack x_{j_{b}} \leq c_b\rbrack$.
  - $\mathcal{M}_h = \{\mu_{ht}\colon t \in \mathcal{L}_h\}$ are leaf node parameters with $\mu_{ht} \in \mathbb{R}$.
]

--

.font75[

- The prior is $\pi(\mathcal{T}_h, \mathcal{M}_h) = \pi_\mathcal{T}(\mathcal{T}_h)\pi_{\mathcal{M}}(\mathcal{M}_h \mid \mathcal{T}_h)$.
  - $\pi_\mathcal{T}(\mathcal{T}_h)$ is a branching process `r Citep(bib, "Chipman1998")`.
  - $\pi_{\mathcal{M}}(\mathcal{M}_h \mid \mathcal{T}_h)=\prod_{t \in \mathcal{L}_h} \pi_\mu(\mu_{ht})$,
where $\pi_\mu$ is chosen so that it is conditionally conjugate.

]

--

.font75[

- Inference on $\{(\mathcal{T}_h, \mathcal{M}_h)\}_{h=1}^m$
is conducted by MCMC using Bayesian backfitting `r Citep(bib, "Hastie2000")`.

- Theoretical guard:
  - Gaussian process limit as $m \rightarrow \infty$ `r Citep(bib, "Linero2017")`.
  - Good rates of posterior convergence `r Citep(bib, "Linero2018", "Rockova2020")`.
]

---
# The BART prior

```{r trees-mateus, out.width="70%", fig.align="center"}
knitr::include_graphics("./figures/trees_from_mmm.png")
```


---
# The ZANIM-BART model

- log-linear BART prior of `r Citet(bib, "Murray2021")` for the *population-level* count probabilities, $\pmb{\theta}$:

$$\theta_{ij} = \frac{f^{(j)}(\mathbf{x}_i)}{\sum_{k=1}^d f^{(k)}(\mathbf{x}_i)},
\quad \textrm{with} \quad
\log f^{(j)}(\mathbf{x}_i) =
\sum_{h=1}^{m_\lambda}\,\log\left\lbrack g\left(\mathbf{x}_i; \mathcal{T}^{(\lambda_j)}_{h},
\Lambda^{(\lambda_j)}_{h}\right)\right\rbrack, \quad j \in \{1, \ldots, d\},$$
where $\mathcal{T}^{(\lambda_j)}_{h}$ denotes the $h$-th binary tree topology
for the category $j$ and 
$\Lambda^{(\lambda_j)}_{h} = \{\lambda_{htj}\colon \mathcal{L}^{(\lambda_j)}_h\}$ 
the corresponding set of leaf node parameters with $\lambda_{htj}>0$.

--

- probit-BART prior of `r Citet(bib, "Chipman2010")` for the *population-level*
structural zero probabilities, $\pmb{\zeta}$:

$$\zeta_{ij} = \Phi\left( f^{(j)}_0(\mathbf{x}_i) \right)
= \Phi\left\lbrack \sum_{h=1}^{m_\zeta} 
g\left(\mathbf{x}_i; \mathcal{T}^{(\zeta_j)}_{h}, \mathcal{M}^{(\zeta_j)}_{h}\right)
\right\rbrack, \quad j\in \{1,\ldots,d\}$$
where $\Phi(\cdot)$ is the cumulative distribution function of a standard normal random variable,
and $\mathcal{T}^{(\zeta_j)}_{h}$ and $\mathcal{M}^{(\zeta_j)}_{h} = \{\mu_{htj}\colon \mathcal{L}^{(\zeta_j)}_h \}$
are the category-specific tree structure and leaf node parameters, respectively.


---
# Incoporating heterogeneity: The ZANIM-LN-BART model

- Include a multivariate Gaussian random effect,
$\mathbf{u}_i = (u_{i1}, \ldots, u_{id}) \sim \operatorname{Normal}_d\left\lbrack \pmb{0}, \pmb{\Sigma}_U \right\rbrack$,
on the *population-level* count probabilities,
$\pmb{\theta}$, as follows:
$$\theta_{ij} = \frac{f^{(j)}(\mathbf{x}_i) e^{u_{ij}}}{\sum_{k=1}^d f^{(j)}(\mathbf{x}_i) e^{u_{ik}}}, \quad
j\in\{1,\ldots,d\}.$$

--

- Identifiability is achieved through a sum-to-zero constraint:
  - $\mathbf{u}_i=\mathbf{B}\mathbf{v}_i$, $\mathbf{v}_i \sim \operatorname{Normal}_{d-1}\left\lbrack \pmb{0}, \pmb{\Sigma}_V \right\rbrack$, where $\mathbf{B}$ is $d\times d-1$ orthogonal matrix, and $\pmb{\Sigma}_U = \mathbf{B} \pmb{\Sigma}_V \mathbf{B}^\top$.
  - Sample from $\mathbf{v}_i$ using elliptical slice sampling
  - Factor analysis hyper-prior on $\pmb{\Sigma}_V$.

$$\mathbf{v}_i = \pmb{\Gamma} \pmb{\eta}_i + \pmb{\epsilon}_i,$$
where $\pmb{\Gamma} = \left\lbrack \gamma_{hj}\right\rbrack_{h=1,\ldots,d-1}^{j=1,\ldots,k}$ is a
$d-1 \times k$ factor loading matrix, 
$\pmb{\eta}_i \sim \operatorname{Normal}_k\lbrack \mathbf{0}_k, \mathbf{I}_k\rbrack$ and
$\pmb{\epsilon}_i \sim \operatorname{Normal}_{d-1}\left\lbrack\mathbf{0}_{d-1}, \pmb{\Psi}\right\rbrack$, with
$\pmb{\Psi}=\operatorname{diag}\left\{ \psi_1, \ldots, \psi_{d-1}\right\}$.

<!-- - Full conditional Gaussian updates are readily available for  -->
<!-- $\pmb{\Gamma}$, $\pmb{\Psi}$, and $\pmb{\eta}_i$. -->

<!-- - The variance of $\mathbf{v}_i$ is decomposed as $\pmb{\Sigma}_V = \pmb{\Gamma} \pmb{\Gamma}^\top + \pmb{\Psi}$. -->


<!-- - Similar formulation is proposed by Zeng et al. (2023) with different identifiability and -->
<!-- hyper-prior choices. -->

---
# Data augmentation

.font70[

- Let $\pmb{f} = (f^{(1)}, \ldots, f^{(d)})$ and $\pmb{f}_0 = (f_0^{(1)}, \ldots, f_0^{(d)})$
denote the independent BART priors that characterise our models.

- Data augmentation scheme of `r Citet(bib, "Menezes2025")`:
$$(\phi_i \mid \mathbf{y}_i, \mathbf{z}_i, \pmb{f})  \overset{\operatorname{ind.}}{\sim}
\operatorname{Gamma}\left\lbrack N_i, \sum_{j=1}^d z_{ij}f^{(j)}(\mathbf{x}_i)e^{u_{ij}}\right\rbrack,
\quad i\in\{1,\ldots,n\}$$
where $z_{ij}  \overset{\operatorname{ind.}}{\sim} \operatorname{Bernoulli}\left\lbrack 1 - \Phi\left(f^{(j)}_0(\mathbf{x}_i)\right)\right\rbrack$. This results in the augmented likelihood:
$$p(\pmb{f}, \pmb{f}_0; \mathbf{y}, \mathbf{x}, \mathbf{u}, \mathbf{z}, \pmb{\phi})
\propto
\prod_{i=1}^n
\prod_{j=1}^d
\left\{
\left\lbrack \Phi\left(f^{(j)}_0(\mathbf{x}_i)\right)\right\rbrack^{1-z_{ij}}
\left\lbrack 1 - \Phi\left( f^{(j)}_0(\mathbf{x}_i)\right)\right\rbrack^{1-z_{ij}}
f^{(j)}(\mathbf{x}_i)^{z_{ij}\,y_{ij}}e^{-\phi_i\,z_{ij}f^{(j)}(\mathbf{x}_i)}
\right\}
p(\mathbf{u}_i; \pmb{\Sigma}_U).$$

- The posterior distribution of $z_{ij}$ is:
$$(z_{ij} \mid y_{ij}, \phi_i, \pmb{f}, \pmb{f}_0) \overset{\operatorname{ind.}}{\sim}
\begin{cases} 1 & \textrm{if} \: y_{ij} > 0\\
\operatorname{Bernoulli}\left\lbrack
\dfrac{\left\lbrack1- \Phi\left( f^{(j)}_0(\mathbf{x}_i)\right) \right\rbrack\,e^{-\phi_iu_{ij}f^{(j)}(\mathbf{x}_i)}
}{\Phi\left( f^{(j)}_0(\mathbf{x}_i)\right) + \left\lbrack 1- \Phi\left( f^{(j)}_0(\mathbf{x}_i)\right) \right\rbrack
e^{-\phi_i u_{ij}f^{(j)}(\mathbf{x}_i)}}
\right\rbrack
& \textrm{if} \: y_{ij} = 0.
\end{cases}$$
]

--

.font70[

- Independent BART updates for each $j\in\{1,\ldots,d\}$:
  - $(\mathcal{T}^{(\lambda_j)}_h, \Lambda_h^{(\lambda_j)})_{h=1}^{m_\lambda}$ using
  `r Citet(bib, "Murray2021")` **generalised Bayesian backfitting** algorithm.
  
  - $(\mathcal{T}^{(\zeta_j)}_h, \mathcal{M}_h^{(\zeta_j)})_{h=1}^{m_\zeta}$ using
  `r Citet(bib, "Chipman2010")` **Bayesian backfitting** algorithm.

]

---
# MCMC algorithm
```{r mcmc-algorithm, out.width="80%"}
knitr::include_graphics(path = "./figures/mcmc_algorithm.png")
```

---
# Simulated example

- Settings: $d = 4$, $n = 400$, $x_i \in \lbrack -1, 1\rbrack$,
$N_i \sim \operatorname{Uniform}\lbrack 100, 500\rbrack$. Count simulated as follows

$$\mathbf{Y}_i \sim \operatorname{Multinomial}\left\lbrack N_i, 
\frac{z_{i1}\theta_{i1}}{\sum_{k=1}^4z_{ik}\theta_{ik}}, \ldots, \frac{z_{i4}\theta_{i4}}{\sum_{k=1}^4z_{ik}\theta_{ik}} \right\rbrack, \quad i\in\{1,\ldots,400\},$$
where $z_{ij} \sim \operatorname{Bernoulli}\lbrack 1 - \zeta_{ij}\rbrack$.

- Functional form of the parameters are given by
$$\theta_{ij} = \frac{f^{(j)}(x_i)}{\sum_{k=1}^d f^{(k)}(x_i)},
\quad \textrm{with} \quad
\log f^{(j)}(x_i) = \sum_{\ell=1}^{b_\lambda} s^{\lambda}_{j\ell}(x_i) \beta_{j\ell},
\quad \textrm{and} \quad
\zeta_{ij} = \Phi\left( \sin(2 \pi x_i) + x_i^2 - \beta^{(\zeta_j)}_{0} \right)$$
where $s^{\lambda}_{j\ell}(\cdot)$
is basis of cubic B-splines with six degrees,
$\beta_{j\ell}$ were sampled from a standard normal distribution, and
$\beta^{(\zeta_j)}_{0} = (0.5, 1.0, 1.5, 2.0)$.

- We compared ZANIM-BART against multinomial-BART model of `r Citet(bib, "Murray2021")`,
and ZANIDM linear regression model of `r Citet(bib, "Koslovsky2023")`.

---
# Simulated example
```{r toy-example}
n_sample <- 400L
n_trials <- sample(seq.int(100L, 500L), n_sample, replace = TRUE)
set.seed(1212)
d <- 4L
dof_bs_theta <- 6L
X <- as.matrix(seq(-1, 1, length.out = n_sample))
X1_bs <- splines::bs(X, dof_bs_theta)
betas_theta <- matrix(stats::rnorm(d * dof_bs_theta), dof_bs_theta, d)
betas_theta[1L, ] <- betas_theta[1L, ] - seq(from = 4, to = 0, length.out = d)
eta_theta <- X1_bs %*% betas_theta
eta_zeta <- matrix(nrow = n_sample, ncol = d)
intercept <- c(0.5, 1.0, 1.5, 2.0)
for (j in seq_len(d)) {
  eta_zeta[, j] <- sin(2 * pi * X[, 1L]) + X[, 1L]^2 - intercept[j]
}
true_zetas <- pnorm(eta_zeta)
alphas <- exp(eta_theta) 
Y <- Z <- true_thetas <- true_varthetas <- matrix(nrow = n_sample, ncol = d)
for (i in seq_len(n_sample)) {
  z <- stats::rbinom(n = d, size = 1L, prob = 1.0 - true_zetas[i, ])
  is_zero <- z == 0L
  p_ij <- alphas[i, ] / sum(alphas[i, ])
  true_thetas[i, ] <- p_ij
  true_varthetas[i, ] <- z * p_ij / sum(z * p_ij)
  if (all(is_zero)) Y[i, ] <- rep(0L, d)
  else if (sum(is_zero) == d - 1L) {
    Y[i, ] <- rep(0L, d)
    Y[i, !is_zero] <- n_trials[i]
  } else {
    Y[i, ] <- stats::rmultinom(n = 1L, size = n_trials[i],
                               prob = true_varthetas[i, ])
  }
  Z[i, ] <- z
}
data_sim <- data.frame(id = rep(seq_len(n_sample), each = d),
                      category = rep(seq_len(d), times = n_sample),
                      x = rep(X[, 1L], each = d),
                      theta = c(t(true_thetas)),
                      zeta = c(t(true_zetas)),
                      total = c(t(Y)), z = c(t(Z)),
                      prop = c(apply(Y, 1L, function(z) z/sum(z))))
data_sim$category_lab <- paste0("j == ", data_sim$category)
data_sim$prop[which(is.na(data_sim$prop))] <- 0.0
ggplot(data_sim, aes(x = x, y = prop)) +
  facet_wrap(~category_lab, labeller = label_parsed) +
  geom_point(alpha = 0.5, aes(col = "y")) +
  geom_line(aes(y = theta, col = "theta")) +
  geom_line(aes(y = zeta, col = "zeta")) +
  labs(y = latex2exp::TeX(r'(Composition, $y_{ij}/N_i$)'),
       x = expression(x[i]), col = "", fill = "") +
  scale_color_manual(
    breaks = c("y", "theta", "zeta"),
    values = c("y" = "black", "theta" = "blue", "zeta" = "red"),
    labels = c("y" = latex2exp::TeX(r'($y_{ij}/N_i$)'),
               "theta"  = latex2exp::TeX(r'($\theta_{ij}$)'),
               "zeta"   = latex2exp::TeX(r'($\zeta_{ij}$)')))
# Import data with the results
tmp <- readRDS(file = "./data/posterior_parameters.rds")
data_theta <- tmp[[1L]]
data_zeta <- tmp[[2L]]
COLORS <- colorspace::qualitative_hcl(3, palette = "Dark 3")
```


---
# Estimation of the *population-level* count probabilities

```{r count-prob}
ggplot(data = data_sim) +
  geom_line(mapping = aes(x = x, y = theta), linewidth = 0.8) +
  facet_wrap(~category_lab, labeller = label_parsed) +
  geom_rug(data = dplyr::filter(data_sim, total == 0L),
           mapping = aes(y = NA_real_, x = x)) +
  geom_line(data = data_theta, mapping = aes(x = x, y = median, col = model)) +
  geom_ribbon(data = data_theta,
              aes(x = x, ymin = ci_lower, ymax = ci_upper, fill = model),
              alpha = 0.3) +
  labs(y = latex2exp::TeX(r'(Count probabilities, $\theta_{ij}$)'),
       x = expression(x[i]), col = "", fill = "") +
  scale_color_manual(values = COLORS) +
  scale_fill_manual(values = COLORS) 
```


---
# Estimation of the *population-level* structural zero probabilities

```{r zero-prob}
ggplot(data = data_sim) +
  geom_line(mapping = aes(x = x, y = zeta), linewidth = 0.8) +
  facet_wrap(~category_lab, labeller = label_parsed) +
  geom_rug(data = dplyr::filter(data_sim, total == 0L),
           mapping = aes(y = NA_real_, x = x)) +
  geom_line(data = data_zeta, mapping = aes(x = x, y = median, col = model)) +
  geom_ribbon(data = data_zeta, aes(x = x, ymin = ci_lower, ymax = ci_upper,
                                    fill = model), alpha = 0.3) +
  labs(y = latex2exp::TeX(r'(Zero-inflation probabilities, $\zeta_{ij}$)'),
       x = expression(x[i]), col = "", fill = "") +
  scale_color_manual(values = COLORS[-1]) +
  scale_fill_manual(values = COLORS[-1]) 
```


---
count: false
class: middle, inverse
# Modern pollen-climate application


---
# Context

- $n=7832$ samples of $d=28$ pollen species collected at different site locations in the 
Northern Hemisphere, along with three climate covariates `r Citep(bib, "Parnell2015")`: 
  - growing degree days above five $5^\circ$ (GDD5): growing season warmth.
  - mean temperature of the coldest month (MTCO): harshness of the winter.
  - ratio of actual to potential evapotranspiration (AET/PET): available moisture.

- **Goal:** to investigate the climate-pollen relationship in a sparse (63% zeros) and highly heterogeneous dataset.

```{r plot-pollen-again, echo = FALSE, out.width="80%", eval=FALSE}
data_pollen |>
  dplyr::filter(specie %in% c("Pinus.D", "Picea")) |>
  ggplot(aes(x = mtco, y = prop)) +
  facet_wrap(~specie) +
  geom_point(alpha = 0.3, size = 0.8) +
  geom_rug(data = dplyr::filter(data_pollen, specie %in% c("Pinus.D", "Picea"),
                                total == 0),
           aes(y = NA_real_), col = "red", alpha = 0.5) +
  labs(y = "Pollen composition", x = "Mean temperature of coldest month (MTCO)")
```

- $m_\lambda = m_\zeta = 100$ trees for $j\in\{1,\ldots, 28\}$. It took $3$ hours for $10,000$ iterations.

---
# Goodness-of-fit

```{r gof-pollen, out.width="80%"}
knitr::include_graphics("./figures/ppc_ecdf_paleoclimate_example.png")
```


---
# Posterior dependence plots: MTCO

```{r pdps}
data_pdp_theta <- readRDS("./data/pdp_theta_picea_pinusd.rds")
data_pdp_zeta <- readRDS("./data/pdp_zeta_picea_pinusd.rds")
chosen_covariates <- c("mtco", "gdd5", "aet.pet")
chosen_taxa <- c("Pinus.D", "Picea")
data_pollen <- dplyr::rename(data_pollen, taxa = specie)
list_plots <- list()
for (k in seq_along(chosen_covariates)) {
  cur_x <- chosen_covariates[k]
  data_cur <- dplyr::filter(data_pdp_theta, covariate == cur_x)
  data_cur_zeta <- dplyr::filter(data_pdp_zeta, covariate == cur_x)
  list_plots[[k]] <- ggplot(dplyr::filter(data_pollen, taxa %in% chosen_taxa)) +
    facet_wrap(~taxa, ncol = 2) +
    geom_point(data = dplyr::filter(data_pollen, taxa %in% chosen_taxa),
               aes(x = !!sym(cur_x), y = prop),
               alpha = 0.2, size = 0.5) +
    geom_rug(data = dplyr::filter(data_pollen, taxa %in% chosen_taxa, total == 0),
             aes(x = !!sym(cur_x), y = NA_real_)) +
    geom_line(data = data_cur, aes(x = x, y = median), col = "dodgerblue") +
    geom_ribbon(data = data_cur, aes(x = x, ymin = ci_lower, ymax = ci_upper),
                fill = "dodgerblue", alpha = 0.4) +
    geom_line(data = data_cur_zeta, aes(x = x, y = median), col = "orange") +
    geom_ribbon(data = data_cur_zeta, aes(x = x, ymin = ci_lower, ymax = ci_upper),
                fill = "orange", alpha = 0.4) +
    labs(y = "Pollen composition", x = toupper(cur_x))
}
list_plots[[1L]]
```

---
# Posterior dependence plots: GDD5
```{r pdp-gdd5}
list_plots[[2L]]
```

---
# Posterior dependence plots: AET/PET
```{r pdp-aet-pet}
list_plots[[3L]]
```



---
# Estimated climate surface: Pinus.D

```{r gdd5-mtco-pinus-d, out.width="100%"}
knitr::include_graphics("./figures/predictions_gdd5_mtco_pinus.d.png")
```

---
# Estimated climate surface: Picea

```{r gdd5-mtco-picea, out.width="100%"}
knitr::include_graphics("./figures/predictions_gdd5_mtco_picea.png")
```


---
# Final remarks


.font90[

**Summary**

  - Probability characterisation for zero-inflation in count-composition data `r Citep(bib, "Menezes2025")`.

  - ZANIM-BART and ZANIM-LN-BART models address key challenges in 
count-compositional data: zero-inflation, overdispersion, cross-sample heterogeneity, 
unknown covariates effects.

  - Developed MCMC algorithm for ZANIM-BART and ZANIM-LN-BART models combining
  ZANIM data augmentation established BART sampling routines.
  
  - Illustrated the useful of our models in the analysis of modern pollen-climate data.
]

--

.font90[

**Future work**
  
  - Integrate our proposed models into the paleoclimate reconstruction framework of `r Citet(bib, "Parnell2015")`.
  
  - Relax the independence across $\mathbf{z}_i$ using the
  probit seemingly unrelated BART (probit-suBART) prior of `r Citet(bib, "Esser2025")`.

  - Incorporate the multiplicative gamma process prior of `r Citet(bib, "Bhattacharya2011")` in ZANIM-LN-BART model.
]


---
count: false
# References

.font60[
```{r bib, results='asis', echo=FALSE}
RefManageR::PrintBibliography(bib, start = 1, end = 11)
```
]

---
count: false
# References

.font60[
```{r bib2, results='asis', echo=FALSE}
RefManageR::PrintBibliography(bib, start = 12, end = 19)
```
]



---
count: false
class: middle, inverse
# Thank you!

.pull-right[

<a href="mailto:andrefelipemaringa@gmail.com">
`r icons::fontawesome("paper-plane")` andrefelipemaringa@gmail.com
</a>

<a href="https://andrmenezes.github.io/casi25">
`r icons::fontawesome("link")` andrmenezes.github.io/ucd_wgsl__2025-11-20
</a>

<a href="http://github.com/AndrMenezes">
`r icons::fontawesome("github")` @AndrMenezes
</a>

<br><br><br><br><br>
]

